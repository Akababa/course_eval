{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "      <th>benefits</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>A. Tupling</td>\n",
       "      <td>Professor</td>\n",
       "      <td>180567.92</td>\n",
       "      <td>519.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>A.Russell Tupling</td>\n",
       "      <td>Professor</td>\n",
       "      <td>166933.16</td>\n",
       "      <td>578.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Abigail Scholer</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>132597.73</td>\n",
       "      <td>373.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Achim Kempf</td>\n",
       "      <td>Professor</td>\n",
       "      <td>187834.44</td>\n",
       "      <td>395.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ada Barlatt</td>\n",
       "      <td>Assistant Professor</td>\n",
       "      <td>102159.48</td>\n",
       "      <td>359.08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title     salary  benefits\n",
       "name                                                       \n",
       "A. Tupling                   Professor  180567.92    519.72\n",
       "A.Russell Tupling            Professor  166933.16    578.96\n",
       "Abigail Scholer    Associate Professor  132597.73    373.00\n",
       "Achim Kempf                  Professor  187834.44    395.88\n",
       "Ada Barlatt        Assistant Professor  102159.48    359.08"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setting up salary data\n",
    "sal=pd.concat([pd.read_csv(f\"salaries/p_{yr}.csv\") for yr in range(2018,2010,-1)])\n",
    "sal=sal.groupby(\"name\").first()\n",
    "sal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>ccode</th>\n",
       "      <th>instructor</th>\n",
       "      <th>organization</th>\n",
       "      <th>expl_lvl</th>\n",
       "      <th>q_treatment</th>\n",
       "      <th>visual</th>\n",
       "      <th>oral</th>\n",
       "      <th>help</th>\n",
       "      <th>interesting</th>\n",
       "      <th>...</th>\n",
       "      <th>printed_notes</th>\n",
       "      <th>textbook</th>\n",
       "      <th>new_material</th>\n",
       "      <th>assign_amount</th>\n",
       "      <th>hours_outside</th>\n",
       "      <th>num_responses</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>title</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1131</td>\n",
       "      <td>['ACTSC 232']</td>\n",
       "      <td>James Adcock</td>\n",
       "      <td>1.360825</td>\n",
       "      <td>2.804124</td>\n",
       "      <td>1.453608</td>\n",
       "      <td>1.567010</td>\n",
       "      <td>1.268041</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.641304</td>\n",
       "      <td>...</td>\n",
       "      <td>1.516129</td>\n",
       "      <td>1.865169</td>\n",
       "      <td>2.659794</td>\n",
       "      <td>2.927835</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>97</td>\n",
       "      <td>143</td>\n",
       "      <td>0.678322</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>136295.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1131</td>\n",
       "      <td>['ACTSC 371']</td>\n",
       "      <td>Brent Matheson</td>\n",
       "      <td>2.221053</td>\n",
       "      <td>2.821053</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.452632</td>\n",
       "      <td>2.242105</td>\n",
       "      <td>2.565217</td>\n",
       "      <td>2.070588</td>\n",
       "      <td>...</td>\n",
       "      <td>1.909091</td>\n",
       "      <td>2.271429</td>\n",
       "      <td>2.851064</td>\n",
       "      <td>3.021277</td>\n",
       "      <td>1.903226</td>\n",
       "      <td>95</td>\n",
       "      <td>236</td>\n",
       "      <td>0.402542</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>128478.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1131</td>\n",
       "      <td>['ACTSC 372']</td>\n",
       "      <td>Peter Wood</td>\n",
       "      <td>1.435644</td>\n",
       "      <td>2.623762</td>\n",
       "      <td>1.400000</td>\n",
       "      <td>1.574257</td>\n",
       "      <td>1.386139</td>\n",
       "      <td>1.712121</td>\n",
       "      <td>1.590000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.785714</td>\n",
       "      <td>2.103896</td>\n",
       "      <td>2.762376</td>\n",
       "      <td>2.891089</td>\n",
       "      <td>1.930000</td>\n",
       "      <td>101</td>\n",
       "      <td>174</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>Lecturer</td>\n",
       "      <td>162561.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1131</td>\n",
       "      <td>['ACTSC 433', 'ACTSC 833']</td>\n",
       "      <td>Jun Cai</td>\n",
       "      <td>1.723077</td>\n",
       "      <td>2.859375</td>\n",
       "      <td>2.262295</td>\n",
       "      <td>1.923077</td>\n",
       "      <td>2.476923</td>\n",
       "      <td>2.352941</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.578947</td>\n",
       "      <td>2.166667</td>\n",
       "      <td>2.907692</td>\n",
       "      <td>2.707692</td>\n",
       "      <td>1.968750</td>\n",
       "      <td>65</td>\n",
       "      <td>107</td>\n",
       "      <td>0.607477</td>\n",
       "      <td>Professor</td>\n",
       "      <td>161277.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1131</td>\n",
       "      <td>['ACTSC 446', 'ACTSC 846']</td>\n",
       "      <td>Ruodo Wang</td>\n",
       "      <td>2.308411</td>\n",
       "      <td>2.557692</td>\n",
       "      <td>1.990566</td>\n",
       "      <td>2.644860</td>\n",
       "      <td>2.679245</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.031250</td>\n",
       "      <td>...</td>\n",
       "      <td>1.819444</td>\n",
       "      <td>2.370968</td>\n",
       "      <td>2.538462</td>\n",
       "      <td>2.844660</td>\n",
       "      <td>2.038095</td>\n",
       "      <td>107</td>\n",
       "      <td>178</td>\n",
       "      <td>0.601124</td>\n",
       "      <td>Associate Professor</td>\n",
       "      <td>141182.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   term                       ccode      instructor  organization  expl_lvl  \\\n",
       "0  1131               ['ACTSC 232']    James Adcock      1.360825  2.804124   \n",
       "1  1131               ['ACTSC 371']  Brent Matheson      2.221053  2.821053   \n",
       "2  1131               ['ACTSC 372']      Peter Wood      1.435644  2.623762   \n",
       "3  1131  ['ACTSC 433', 'ACTSC 833']         Jun Cai      1.723077  2.859375   \n",
       "4  1131  ['ACTSC 446', 'ACTSC 846']      Ruodo Wang      2.308411  2.557692   \n",
       "\n",
       "   q_treatment    visual      oral      help  interesting  ...  printed_notes  \\\n",
       "0     1.453608  1.567010  1.268041  2.000000     1.641304  ...       1.516129   \n",
       "1     2.000000  2.452632  2.242105  2.565217     2.070588  ...       1.909091   \n",
       "2     1.400000  1.574257  1.386139  1.712121     1.590000  ...       1.785714   \n",
       "3     2.262295  1.923077  2.476923  2.352941     1.833333  ...       1.578947   \n",
       "4     1.990566  2.644860  2.679245  2.000000     2.031250  ...       1.819444   \n",
       "\n",
       "   textbook  new_material  assign_amount  hours_outside  num_responses  \\\n",
       "0  1.865169      2.659794       2.927835       2.000000             97   \n",
       "1  2.271429      2.851064       3.021277       1.903226             95   \n",
       "2  2.103896      2.762376       2.891089       1.930000            101   \n",
       "3  2.166667      2.907692       2.707692       1.968750             65   \n",
       "4  2.370968      2.538462       2.844660       2.038095            107   \n",
       "\n",
       "   enrolled  response_rate                title     salary  \n",
       "0       143       0.678322             Lecturer  136295.28  \n",
       "1       236       0.402542             Lecturer  128478.60  \n",
       "2       174       0.580460             Lecturer  162561.88  \n",
       "3       107       0.607477            Professor  161277.18  \n",
       "4       178       0.601124  Associate Professor  141182.60  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up dataframes\n",
    "eval_data = pd.read_csv(\"averages.csv\")\n",
    "eval_data[[\"term\"]]=pd.Categorical(eval_data.term)\n",
    "eval_data[[\"section\"]]=pd.Categorical(eval_data.section)\n",
    "eval_data[\"response_rate\"] = eval_data.num_responses / eval_data.enrolled\n",
    "df.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "df=eval_data[eval_data.num_responses>10] # only surveys with >10 responses\n",
    "df=df.groupby(\"instructor\").filter(lambda x:len(x)>2) # only teachers with >=3 classes\n",
    "df=pd.merge(df,sal,how='left', left_on=[\"instructor\"],right_on=['name']).drop(['benefits',\"section\"],axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>organization</th>\n",
       "      <th>expl_lvl</th>\n",
       "      <th>q_treatment</th>\n",
       "      <th>visual</th>\n",
       "      <th>oral</th>\n",
       "      <th>help</th>\n",
       "      <th>interesting</th>\n",
       "      <th>overall</th>\n",
       "      <th>attendance</th>\n",
       "      <th>assign_helpful</th>\n",
       "      <th>...</th>\n",
       "      <th>textbook</th>\n",
       "      <th>new_material</th>\n",
       "      <th>assign_amount</th>\n",
       "      <th>hours_outside</th>\n",
       "      <th>num_responses</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>response_rate</th>\n",
       "      <th>salary</th>\n",
       "      <th>num_taught</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instructor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Adam Kolkiewicz</td>\n",
       "      <td>1.691446</td>\n",
       "      <td>2.429451</td>\n",
       "      <td>1.510890</td>\n",
       "      <td>1.950600</td>\n",
       "      <td>1.885041</td>\n",
       "      <td>1.362193</td>\n",
       "      <td>1.635859</td>\n",
       "      <td>1.561237</td>\n",
       "      <td>1.243845</td>\n",
       "      <td>1.470170</td>\n",
       "      <td>...</td>\n",
       "      <td>1.550505</td>\n",
       "      <td>2.583002</td>\n",
       "      <td>2.639731</td>\n",
       "      <td>2.495896</td>\n",
       "      <td>29.00</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>0.446812</td>\n",
       "      <td>175958.2</td>\n",
       "      <td>3</td>\n",
       "      <td>Associate Professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Adam Roegiest</td>\n",
       "      <td>1.862390</td>\n",
       "      <td>2.794451</td>\n",
       "      <td>1.832141</td>\n",
       "      <td>2.112739</td>\n",
       "      <td>1.795893</td>\n",
       "      <td>2.033704</td>\n",
       "      <td>1.717994</td>\n",
       "      <td>1.856250</td>\n",
       "      <td>1.278992</td>\n",
       "      <td>1.531858</td>\n",
       "      <td>...</td>\n",
       "      <td>2.391384</td>\n",
       "      <td>2.577641</td>\n",
       "      <td>2.122081</td>\n",
       "      <td>3.652393</td>\n",
       "      <td>51.75</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>0.583992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Adriel Dean-Hall</td>\n",
       "      <td>2.314286</td>\n",
       "      <td>3.033968</td>\n",
       "      <td>2.013506</td>\n",
       "      <td>2.449048</td>\n",
       "      <td>2.227879</td>\n",
       "      <td>2.418803</td>\n",
       "      <td>1.849768</td>\n",
       "      <td>2.234791</td>\n",
       "      <td>1.599206</td>\n",
       "      <td>1.598413</td>\n",
       "      <td>...</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>2.777233</td>\n",
       "      <td>2.349206</td>\n",
       "      <td>3.241270</td>\n",
       "      <td>25.00</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>0.359124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ahmad Alrefai</td>\n",
       "      <td>3.056345</td>\n",
       "      <td>3.086275</td>\n",
       "      <td>2.738697</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.419231</td>\n",
       "      <td>1.827778</td>\n",
       "      <td>1.891059</td>\n",
       "      <td>3.225774</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>1.709017</td>\n",
       "      <td>...</td>\n",
       "      <td>2.236467</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.300389</td>\n",
       "      <td>3.327778</td>\n",
       "      <td>32.00</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.558923</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ahmed Ayaz Ataullah</td>\n",
       "      <td>2.038713</td>\n",
       "      <td>2.891438</td>\n",
       "      <td>1.781366</td>\n",
       "      <td>2.207169</td>\n",
       "      <td>2.030823</td>\n",
       "      <td>2.069040</td>\n",
       "      <td>2.168041</td>\n",
       "      <td>1.939435</td>\n",
       "      <td>1.687095</td>\n",
       "      <td>1.855265</td>\n",
       "      <td>...</td>\n",
       "      <td>2.356944</td>\n",
       "      <td>2.887103</td>\n",
       "      <td>2.975629</td>\n",
       "      <td>1.891201</td>\n",
       "      <td>51.00</td>\n",
       "      <td>98.166667</td>\n",
       "      <td>0.525865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     organization  expl_lvl  q_treatment    visual      oral  \\\n",
       "instructor                                                                     \n",
       "Adam Kolkiewicz          1.691446  2.429451     1.510890  1.950600  1.885041   \n",
       "Adam Roegiest            1.862390  2.794451     1.832141  2.112739  1.795893   \n",
       "Adriel Dean-Hall         2.314286  3.033968     2.013506  2.449048  2.227879   \n",
       "Ahmad Alrefai            3.056345  3.086275     2.738697  3.266667  3.419231   \n",
       "Ahmed Ayaz Ataullah      2.038713  2.891438     1.781366  2.207169  2.030823   \n",
       "\n",
       "                         help  interesting   overall  attendance  \\\n",
       "instructor                                                         \n",
       "Adam Kolkiewicz      1.362193     1.635859  1.561237    1.243845   \n",
       "Adam Roegiest        2.033704     1.717994  1.856250    1.278992   \n",
       "Adriel Dean-Hall     2.418803     1.849768  2.234791    1.599206   \n",
       "Ahmad Alrefai        1.827778     1.891059  3.225774    1.857143   \n",
       "Ahmed Ayaz Ataullah  2.069040     2.168041  1.939435    1.687095   \n",
       "\n",
       "                     assign_helpful  ...  textbook  new_material  \\\n",
       "instructor                           ...                           \n",
       "Adam Kolkiewicz            1.470170  ...  1.550505      2.583002   \n",
       "Adam Roegiest              1.531858  ...  2.391384      2.577641   \n",
       "Adriel Dean-Hall           1.598413  ...  2.055556      2.777233   \n",
       "Ahmad Alrefai              1.709017  ...  2.236467      2.333333   \n",
       "Ahmed Ayaz Ataullah        1.855265  ...  2.356944      2.887103   \n",
       "\n",
       "                     assign_amount  hours_outside  num_responses   enrolled  \\\n",
       "instructor                                                                    \n",
       "Adam Kolkiewicz           2.639731       2.495896          29.00  72.333333   \n",
       "Adam Roegiest             2.122081       3.652393          51.75  90.500000   \n",
       "Adriel Dean-Hall          2.349206       3.241270          25.00  69.333333   \n",
       "Ahmad Alrefai             2.300389       3.327778          32.00  53.000000   \n",
       "Ahmed Ayaz Ataullah       2.975629       1.891201          51.00  98.166667   \n",
       "\n",
       "                     response_rate    salary  num_taught                title  \n",
       "instructor                                                                     \n",
       "Adam Kolkiewicz           0.446812  175958.2           3  Associate Professor  \n",
       "Adam Roegiest             0.583992       NaN           4                  NaN  \n",
       "Adriel Dean-Hall          0.359124       NaN           3                  NaN  \n",
       "Ahmad Alrefai             0.558923       NaN           3                  NaN  \n",
       "Ahmed Ayaz Ataullah       0.525865       NaN           6                  NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tenure=df.groupby(\"instructor\").mean()\n",
    "df_tenure[\"num_taught\"]=df.groupby(\"instructor\").size()\n",
    "df_tenure[\"title\"]=df.groupby(\"instructor\").first()[[\"title\"]]\n",
    "has_tenure=df_tenure.title.isin([\"Professor\",\"Associate Professor\"])\n",
    "\n",
    "df_tenure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up of names and classifiers \n",
    "names = [\"Nearest Neighbors\", \"SVM tuned\",\n",
    "         \"Decision Tree\", \"Random Forest\",\"AdaBoost\",\n",
    "         \"Naive Bayes\",\"LDA\",\"QDA\",\"LogReg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#grid search for parameter selection of certain estimators\n",
    "## SVC grid search\n",
    "param_grid_SVC = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    " ]\n",
    "\n",
    "SVC_clf = RandomizedSearchCV(SVC(), param_grid_SVC, cv=5,iid=False)\n",
    "\n",
    "#RF\n",
    "param_grid_RF = [\n",
    " {'bootstrap': [True, False],\n",
    " 'max_depth':[10,20,30,40,50,80,100],\n",
    " 'max_features':['auto',None],\n",
    " 'min_samples_leaf': [1,2,3],\n",
    " 'min_samples_split': [2,5,10],\n",
    " 'n_estimators': [200,400,800,1000,2000]}\n",
    " ]\n",
    "\n",
    "RF_clf = RandomizedSearchCV(RandomForestClassifier(),param_grid_RF,cv=5,iid=False)\n",
    "\n",
    "param_grid_DT = [\n",
    " {'criterion': ['gini','entropy'],\n",
    "  'splitter': ['best','random'],\n",
    " 'max_depth': [10,20,30,40,50,80,100],\n",
    " 'max_features': ['auto',None],\n",
    " 'min_samples_leaf': [1,2,3],\n",
    " 'min_samples_split': [2,5,10],\n",
    " 'n_estimators': [200,400,800,1000,2000]}\n",
    " ]\n",
    "\n",
    "DT_clf = RandomizedSearchCV(DecisionTreeClassifier(),param_grid_DT,cv=5,iid=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(10),\n",
    "    #SVC_clf,\n",
    "    #DecisionTreeClassifier(max_depth = 5 ,criterion = 'gini', splitter='best',max_features='auto'),\n",
    "    #RF_clf,\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver='newton-cg')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['organization', 'expl_lvl', 'q_treatment', 'visual', 'oral', 'help', 'interesting', 'overall', 'attendance', 'assign_helpful', 'printed_notes', 'textbook', 'new_material', 'assign_amount', 'hours_outside', 'num_responses', 'enrolled', 'response_rate', 'num_taught']\n"
     ]
    }
   ],
   "source": [
    "feats=list(df_tenure.select_dtypes('number').columns)\n",
    "feats.remove(\"salary\")\n",
    "\n",
    "print(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-ad9f6fe3bf1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#standardize the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mdf_tenure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeats\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    637\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 639\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 663\u001b[1;33m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[0;32m    664\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    665\u001b[0m         \u001b[1;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 542\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[0;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'infinity'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'NaN, infinity'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "#standardize the data\n",
    "X= df_tenure\n",
    "X=StandardScaler().fit_transform(X[feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-89ff77eb0fa4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifier\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtrain_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    686\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1467\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[0;32m   1468\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1469\u001b[1;33m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    651\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 652\u001b[1;33m                 \u001b[0mcandidate_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    653\u001b[0m                 \u001b[0mn_candidates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# in this case we want to sample without replacement\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         all_lists = np.all([not hasattr(v, \"rvs\")\n\u001b[1;32m--> 252\u001b[1;33m                             for v in self.param_distributions.values()])\n\u001b[0m\u001b[0;32m    253\u001b[0m         \u001b[0mrnd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,has_tenure,test_size=0.3,random_state=42)\n",
    "\n",
    "output = pd.DataFrame(index = ['train error', 'test_error', 'base_line', 'score']) \n",
    "\n",
    "for name,classifier in zip(names,classifiers):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    train_err = np.mean(classifier.predict(X_train)!=y_train)\n",
    "    test_err = np.mean(classifier.predict(X_test)!=y_test)\n",
    "    baseline = np.mean(has_tenure)\n",
    "    output_l = [train_err, test_err, baseline, score]\n",
    "    output[f\"{name}\"] = output_l\n",
    "#     print(f\"train error: {np.mean(clf.predict(X_train)!=y_train)}\")\n",
    "#     print(f\"test error:  {np.mean(clf.predict(X_test)!=y_test)}\")\n",
    "#     print(f\"baseline:    {np.mean(has_tenure)}\")\n",
    "#print(output_l)\n",
    "print(output)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "l1_ratio must be between 0 and 1; got (l1_ratio=None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-05f296eaa5ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'train error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'base_line'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"saga\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"elasticnet\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1500\u001b[0m                     self.l1_ratio < 0 or self.l1_ratio > 1):\n\u001b[0;32m   1501\u001b[0m                         raise ValueError(\"l1_ratio must be between 0 and 1;\"\n\u001b[1;32m-> 1502\u001b[1;33m                                          \" got (l1_ratio=%r)\" % self.l1_ratio)\n\u001b[0m\u001b[0;32m   1503\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml1_ratio\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1504\u001b[0m             warnings.warn(\"l1_ratio parameter is only used when penalty is \"\n",
      "\u001b[1;31mValueError\u001b[0m: l1_ratio must be between 0 and 1; got (l1_ratio=None)"
     ]
    }
   ],
   "source": [
    "output = pd.DataFrame(index = ['train error', 'test_error', 'base_line', 'score']) \n",
    "classifier = LogisticRegression(solver=\"saga\",penalty=\"elasticnet\")\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test,y_test)\n",
    "train_err = np.mean(classifier.predict(X_train)!=y_train)\n",
    "test_err = np.mean(classifier.predict(X_test)!=y_test)\n",
    "baseline = np.mean(has_tenure)\n",
    "print(score)\n",
    "print(train_err)\n",
    "print(test_err)\n",
    "print(baseline)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Nearest Neighbors  SVM tuned  Decision Tree  Random Forest  \\\n",
      "train error           0.268293   0.239837       0.182927       0.020325   \n",
      "test_error            0.311321   0.283019       0.311321       0.283019   \n",
      "base_line             0.423295   0.423295       0.423295       0.423295   \n",
      "score                 0.688679   0.716981       0.688679       0.716981   \n",
      "\n",
      "             AdaBoost  Naive Bayes       LDA       QDA    LogReg  \n",
      "train error  0.077236     0.243902  0.239837  0.199187  0.256098  \n",
      "test_error   0.283019     0.283019  0.273585  0.301887  0.283019  \n",
      "base_line    0.423295     0.423295  0.423295  0.423295  0.423295  \n",
      "score        0.716981     0.716981  0.726415  0.698113  0.716981  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X= df_tenure\n",
    "X=StandardScaler().fit_transform(X[feats])\n",
    "X = PCA(.95).fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,has_tenure,test_size=0.3,random_state=42)\n",
    "\n",
    "output = pd.DataFrame(index = ['train error', 'test_error', 'base_line', 'score']) \n",
    "\n",
    "for name,classifier in zip(names,classifiers):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    train_err = np.mean(classifier.predict(X_train)!=y_train)\n",
    "    test_err = np.mean(classifier.predict(X_test)!=y_test)\n",
    "    baseline = np.mean(has_tenure)\n",
    "    output_l = [train_err, test_err, baseline, score]\n",
    "    output[f\"{name}\"] = output_l\n",
    "#     print(f\"train error: {np.mean(clf.predict(X_train)!=y_train)}\")\n",
    "#     print(f\"test error:  {np.mean(clf.predict(X_test)!=y_test)}\")\n",
    "#     print(f\"baseline:    {np.mean(has_tenure)}\")\n",
    "#print(output_l)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
