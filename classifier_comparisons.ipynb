{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>organization</th>\n",
       "      <th>expl_lvl</th>\n",
       "      <th>q_treatment</th>\n",
       "      <th>visual</th>\n",
       "      <th>oral</th>\n",
       "      <th>help</th>\n",
       "      <th>interesting</th>\n",
       "      <th>overall</th>\n",
       "      <th>attendance</th>\n",
       "      <th>...</th>\n",
       "      <th>printed_notes</th>\n",
       "      <th>textbook</th>\n",
       "      <th>new_material</th>\n",
       "      <th>assign_amount</th>\n",
       "      <th>hours_outside</th>\n",
       "      <th>num_responses</th>\n",
       "      <th>enrolled</th>\n",
       "      <th>salary</th>\n",
       "      <th>num_taught</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instructor</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Adam Kolkiewicz</td>\n",
       "      <td>1173.000000</td>\n",
       "      <td>1.691446</td>\n",
       "      <td>2.429451</td>\n",
       "      <td>1.510890</td>\n",
       "      <td>1.950600</td>\n",
       "      <td>1.885041</td>\n",
       "      <td>1.362193</td>\n",
       "      <td>1.635859</td>\n",
       "      <td>1.561237</td>\n",
       "      <td>1.243845</td>\n",
       "      <td>...</td>\n",
       "      <td>1.471251</td>\n",
       "      <td>1.550505</td>\n",
       "      <td>2.583002</td>\n",
       "      <td>2.639731</td>\n",
       "      <td>2.495896</td>\n",
       "      <td>29.00</td>\n",
       "      <td>72.333333</td>\n",
       "      <td>175958.2</td>\n",
       "      <td>3</td>\n",
       "      <td>Associate Professor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Adam Roegiest</td>\n",
       "      <td>1154.000000</td>\n",
       "      <td>1.862390</td>\n",
       "      <td>2.794451</td>\n",
       "      <td>1.832141</td>\n",
       "      <td>2.112739</td>\n",
       "      <td>1.795893</td>\n",
       "      <td>2.033704</td>\n",
       "      <td>1.717994</td>\n",
       "      <td>1.856250</td>\n",
       "      <td>1.278992</td>\n",
       "      <td>...</td>\n",
       "      <td>2.032509</td>\n",
       "      <td>2.391384</td>\n",
       "      <td>2.577641</td>\n",
       "      <td>2.122081</td>\n",
       "      <td>3.652393</td>\n",
       "      <td>51.75</td>\n",
       "      <td>90.500000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Adriel Dean-Hall</td>\n",
       "      <td>1139.666667</td>\n",
       "      <td>2.314286</td>\n",
       "      <td>3.033968</td>\n",
       "      <td>2.013506</td>\n",
       "      <td>2.449048</td>\n",
       "      <td>2.227879</td>\n",
       "      <td>2.418803</td>\n",
       "      <td>1.849768</td>\n",
       "      <td>2.234791</td>\n",
       "      <td>1.599206</td>\n",
       "      <td>...</td>\n",
       "      <td>1.792929</td>\n",
       "      <td>2.055556</td>\n",
       "      <td>2.777233</td>\n",
       "      <td>2.349206</td>\n",
       "      <td>3.241270</td>\n",
       "      <td>25.00</td>\n",
       "      <td>69.333333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ahmad Alrefai</td>\n",
       "      <td>1176.333333</td>\n",
       "      <td>3.056345</td>\n",
       "      <td>3.086275</td>\n",
       "      <td>2.738697</td>\n",
       "      <td>3.266667</td>\n",
       "      <td>3.419231</td>\n",
       "      <td>1.827778</td>\n",
       "      <td>1.891059</td>\n",
       "      <td>3.225774</td>\n",
       "      <td>1.857143</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039683</td>\n",
       "      <td>2.236467</td>\n",
       "      <td>2.333333</td>\n",
       "      <td>2.300389</td>\n",
       "      <td>3.327778</td>\n",
       "      <td>32.00</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Ahmed Ayaz Ataullah</td>\n",
       "      <td>1148.000000</td>\n",
       "      <td>2.038713</td>\n",
       "      <td>2.891438</td>\n",
       "      <td>1.781366</td>\n",
       "      <td>2.207169</td>\n",
       "      <td>2.030823</td>\n",
       "      <td>2.069040</td>\n",
       "      <td>2.168041</td>\n",
       "      <td>1.939435</td>\n",
       "      <td>1.687095</td>\n",
       "      <td>...</td>\n",
       "      <td>1.856527</td>\n",
       "      <td>2.356944</td>\n",
       "      <td>2.887103</td>\n",
       "      <td>2.975629</td>\n",
       "      <td>1.891201</td>\n",
       "      <td>51.00</td>\n",
       "      <td>98.166667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            term  organization  expl_lvl  q_treatment  \\\n",
       "instructor                                                              \n",
       "Adam Kolkiewicz      1173.000000      1.691446  2.429451     1.510890   \n",
       "Adam Roegiest        1154.000000      1.862390  2.794451     1.832141   \n",
       "Adriel Dean-Hall     1139.666667      2.314286  3.033968     2.013506   \n",
       "Ahmad Alrefai        1176.333333      3.056345  3.086275     2.738697   \n",
       "Ahmed Ayaz Ataullah  1148.000000      2.038713  2.891438     1.781366   \n",
       "\n",
       "                       visual      oral      help  interesting   overall  \\\n",
       "instructor                                                                 \n",
       "Adam Kolkiewicz      1.950600  1.885041  1.362193     1.635859  1.561237   \n",
       "Adam Roegiest        2.112739  1.795893  2.033704     1.717994  1.856250   \n",
       "Adriel Dean-Hall     2.449048  2.227879  2.418803     1.849768  2.234791   \n",
       "Ahmad Alrefai        3.266667  3.419231  1.827778     1.891059  3.225774   \n",
       "Ahmed Ayaz Ataullah  2.207169  2.030823  2.069040     2.168041  1.939435   \n",
       "\n",
       "                     attendance  ...  printed_notes  textbook  new_material  \\\n",
       "instructor                       ...                                          \n",
       "Adam Kolkiewicz        1.243845  ...       1.471251  1.550505      2.583002   \n",
       "Adam Roegiest          1.278992  ...       2.032509  2.391384      2.577641   \n",
       "Adriel Dean-Hall       1.599206  ...       1.792929  2.055556      2.777233   \n",
       "Ahmad Alrefai          1.857143  ...       2.039683  2.236467      2.333333   \n",
       "Ahmed Ayaz Ataullah    1.687095  ...       1.856527  2.356944      2.887103   \n",
       "\n",
       "                     assign_amount  hours_outside  num_responses   enrolled  \\\n",
       "instructor                                                                    \n",
       "Adam Kolkiewicz           2.639731       2.495896          29.00  72.333333   \n",
       "Adam Roegiest             2.122081       3.652393          51.75  90.500000   \n",
       "Adriel Dean-Hall          2.349206       3.241270          25.00  69.333333   \n",
       "Ahmad Alrefai             2.300389       3.327778          32.00  53.000000   \n",
       "Ahmed Ayaz Ataullah       2.975629       1.891201          51.00  98.166667   \n",
       "\n",
       "                       salary  num_taught                title  \n",
       "instructor                                                      \n",
       "Adam Kolkiewicz      175958.2           3  Associate Professor  \n",
       "Adam Roegiest             NaN           4                  NaN  \n",
       "Adriel Dean-Hall          NaN           3                  NaN  \n",
       "Ahmad Alrefai             NaN           3                  NaN  \n",
       "Ahmed Ayaz Ataullah       NaN           6                  NaN  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up dataframes\n",
    "\n",
    "eval_data = pd.read_csv(\"averages.csv\")\n",
    "sal=pd.concat([pd.read_csv(f\"salaries/p_{yr}.csv\") for yr in range(2018,2010,-1)])\n",
    "sal=sal.groupby(\"name\").first()\n",
    "\n",
    "\n",
    "df=eval_data[eval_data.num_responses>10] # only surveys with >10 responses\n",
    "df=df.groupby(\"instructor\").filter(lambda x:len(x)>2) # only teachers with >=3 classes\n",
    "df=pd.merge(df,sal,how='left', left_on=[\"instructor\"],right_on=['name']).drop(['benefits',\"section\"],axis=1)\n",
    "\n",
    "\n",
    "#df_tenure= df[~df.title.isna()]\n",
    "df_tenure=df.groupby(\"instructor\").mean()\n",
    "df_tenure[\"num_taught\"]=df.groupby(\"instructor\").size()\n",
    "df_tenure[\"title\"]=df.groupby(\"instructor\").first()[[\"title\"]]\n",
    "# dfp=dfp.reset_index()\n",
    "has_tenure=df_tenure.title.isin([\"Professor\",\"Associate Professor\"])\n",
    "\n",
    "df_tenure.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up of names and classifiers \n",
    "names = [\"Nearest Neighbors\", \"SVM tuned\",\n",
    "         \"Decision Tree\", \"Random Forest\",\"AdaBoost\",\n",
    "         \"Naive Bayes\",\"LDA\",\"QDA\",\"LogReg\"]\n",
    "\n",
    "#grid search for parameter selection of certain estimators\n",
    "## SVC grid search\n",
    "param_grid_SVC = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    " ]\n",
    "\n",
    "SVC_clf = GridSearchCV(SVC(), param_grid_SVC, cv=5,iid=False)\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(10),\n",
    "    SVC_clf,\n",
    "    DecisionTreeClassifier(max_depth = 5 ,criterion = 'gini', splitter='best',max_features='auto'),\n",
    "    RandomForestClassifier(n_estimators=10),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    LogisticRegression(solver='newton-cg')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Nearest Neighbors  SVM tuned  Decision Tree  Random Forest  \\\n",
      "train error           0.276423   0.239837       0.174797       0.016260   \n",
      "test_error            0.283019   0.301887       0.283019       0.386792   \n",
      "base_line             0.423295   0.423295       0.423295       0.423295   \n",
      "score                 0.716981   0.698113       0.716981       0.613208   \n",
      "\n",
      "             AdaBoost  Naive Bayes       LDA       QDA    LogReg  \n",
      "train error  0.069106     0.317073  0.239837  0.138211  0.243902  \n",
      "test_error   0.349057     0.301887  0.320755  0.254717  0.330189  \n",
      "base_line    0.423295     0.423295  0.423295  0.423295  0.423295  \n",
      "score        0.650943     0.698113  0.679245  0.745283  0.669811  \n"
     ]
    }
   ],
   "source": [
    "feats=list(df_tenure.select_dtypes('number').columns)\n",
    "feats.remove(\"salary\")\n",
    "\n",
    "X= df_tenure\n",
    "X=StandardScaler().fit_transform(X[feats])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,has_tenure,test_size=0.3,random_state=42)\n",
    "\n",
    "output = pd.DataFrame(index = ['train error', 'test_error', 'base_line', 'score']) \n",
    "\n",
    "for name,classifier in zip(names,classifiers):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    train_err = np.mean(classifier.predict(X_train)!=y_train)\n",
    "    test_err = np.mean(classifier.predict(X_test)!=y_test)\n",
    "    baseline = np.mean(has_tenure)\n",
    "    output_l = [train_err, test_err, baseline, score]\n",
    "    output[f\"{name}\"] = output_l\n",
    "#     print(f\"train error: {np.mean(clf.predict(X_train)!=y_train)}\")\n",
    "#     print(f\"test error:  {np.mean(clf.predict(X_test)!=y_test)}\")\n",
    "#     print(f\"baseline:    {np.mean(has_tenure)}\")\n",
    "#print(output_l)\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Nearest Neighbors  SVM tuned  Decision Tree  Random Forest  \\\n",
      "train error           0.268293   0.239837       0.182927       0.020325   \n",
      "test_error            0.311321   0.283019       0.311321       0.283019   \n",
      "base_line             0.423295   0.423295       0.423295       0.423295   \n",
      "score                 0.688679   0.716981       0.688679       0.716981   \n",
      "\n",
      "             AdaBoost  Naive Bayes       LDA       QDA    LogReg  \n",
      "train error  0.077236     0.243902  0.239837  0.199187  0.256098  \n",
      "test_error   0.283019     0.283019  0.273585  0.301887  0.283019  \n",
      "base_line    0.423295     0.423295  0.423295  0.423295  0.423295  \n",
      "score        0.716981     0.716981  0.726415  0.698113  0.716981  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "X= df_tenure\n",
    "X=StandardScaler().fit_transform(X[feats])\n",
    "X = PCA(.95).fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,has_tenure,test_size=0.3,random_state=42)\n",
    "\n",
    "output = pd.DataFrame(index = ['train error', 'test_error', 'base_line', 'score']) \n",
    "\n",
    "for name,classifier in zip(names,classifiers):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test,y_test)\n",
    "    train_err = np.mean(classifier.predict(X_train)!=y_train)\n",
    "    test_err = np.mean(classifier.predict(X_test)!=y_test)\n",
    "    baseline = np.mean(has_tenure)\n",
    "    output_l = [train_err, test_err, baseline, score]\n",
    "    output[f\"{name}\"] = output_l\n",
    "#     print(f\"train error: {np.mean(clf.predict(X_train)!=y_train)}\")\n",
    "#     print(f\"test error:  {np.mean(clf.predict(X_test)!=y_test)}\")\n",
    "#     print(f\"baseline:    {np.mean(has_tenure)}\")\n",
    "#print(output_l)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
