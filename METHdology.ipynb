{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methdology\n",
    "Data classification is not being used to solve a problem, but as part of the analysis of course evaluations. Thus, many types of classifiers were used to compare them with each other and see how the data interacts with different classifiers. The classifiers used are: K-Nearest Neighbours, Support Vector Machine Classifier, Decision Tree, Random Forest, AdaBoost, XGBoost, Navie Bayes, Linear and Quadratic Discriminant Analysis, and Logistic Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours\n",
    "K-Nearest Neighbours or KNN is a supervised learning technique where a point is assigned the majority class of it's K closest neighbouring points. In this classification, k = 10 was used to avoid overfitting the data and causing unecessarily high test error. This was picked as one of the first classifiers due to it's relative simplicity, and feasibility on the size of the available dataset. If the size of the dataset were too big, it would be very computationally intensive to use KNN and perhaps infeasible. Another benefit is the low dimensionality of the data which would otherwise cause the distance between points to be very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
