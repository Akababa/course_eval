{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methdology\n",
    "Data classification is not being used to solve a problem, but as part of the analysis of course evaluations. Thus, many types of classifiers were used to compare them with each other and see how the data interacts with different classifiers. The classifiers used are: K-Nearest Neighbours, Support Vector Machine Classifier, Decision Tree, Random Forest, AdaBoost, XGBoost, Navie Bayes, Linear and Quadratic Discriminant Analysis, and Logistic Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbours\n",
    "K-Nearest Neighbours or KNN is a supervised learning technique where a point is assigned the majority class of it's K closest neighbouring points. In this classification, k = 10 was used to avoid overfitting the data and causing unecessarily high test error. This was picked as one of the first classifiers due to it's relative simplicity, and feasibility on the size of the available dataset. If the size of the dataset were too big, it would be very computationally intensive to use KNN and perhaps infeasible. Another benefit is the low dimensionality of the data which would otherwise cause the distance between points to be very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Classifier\n",
    "The support vector classifier (SVC) is a way of generating hyperplanes as boundaries when linear boundaries can not be directly generated in the original feature space. It does so by generating hyperplanes as linear boundaries in a largely expanded feature space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Tree\n",
    "The classification is done by growing a decision tree recursively by using binary splitting by feature at the nodes until the terminal nodes are reached. The input data is split into non-overlapping region. Then, the classifier assigns an observation to the most common class within an area in the feature space, represented by the leaf nodes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest \n",
    "The random forest algorithm uses classification trees to classify the data. It builds many decision trees on bootstrapped training samples. For each tree  a random fixed size subset of the predictors is selected to build the tree which decorrelates the trees as the trees do not consider all predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost \n",
    "AdaBoost is a boosting algorithm that creates an ensemble of many weak learners to vote on what class an observation will be. Through each iteration, the weight of an observation is changed depending on whether it was misclassified or not. In the first iteration all observations start at an equal weight. The final vote is weight vote by the accuracy of the different classifiers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extreme Gradient Boosting\n",
    "Also known as XGBoost is a popular gradient boosting algorithm. Like Adaboost it uses an ensemble of weak learners, but instead of changing weights of observations, gradient descent is used to minimize a loss function for each new added learner. A special part of xgboost is a penalty on the complexity of the underlying learners ( in this case decision trees)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "The Naive Bayes classifier is conditional probability model and an application of Bayes' theorem with the assumption of independence between features ( hence naive). In this implementation, we are using the gaussian naive bayes where the continuous predictors are assumed to have a normal distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis\n",
    "Linear Discriminant Analysis (LDA) is a generative classifier and another use of Bayes' theorem for classification. In LDA, distributions of each predictor is estimated then Bayes' theorem is used to generate the conditional probabilities. It's commonly used as dimensionality reduction as it creates a feature space where the classes are most separable . Hyperplanes are generated between the classes to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quadratic Discrimininant Analysis\n",
    "QDA is an extension of LDA where the variance-covaraince matrices of predictors are no longer assumed to be all equal. This creates quadratic hyperplanes as decision boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Logistic regression is a regression model that uses the logistic function to model the probability of the class of an observation based on the log ratios.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "In this report, classification was not used to find a solution to the posed problem, but rather as analysis of the data and how it interacts with different classifiers. Thus, many classifiers were used to compare against each other. The data was classified in three different ways. One on class labels being separated into tenured and untenured where employees with the titles \"Associate Professor\" and \"Professor\" fell into tenured and the remaining into untenured. Then the same classification was done except on a principle component analysis transformed data set. Lastly the original dataset was classified with the actual titles of employees: Professor, Associate Professor, Assitant Professor, and Lecturer. \n",
    "\n",
    "For a select set of the classifiers (SVC,Random Forest, Decision Tree, XGBoost) 5-fold cross validation grid/random search was used to tune the hyperparameters. The others were left as is using certain default methods as they have relatively few parameters.\n",
    "\n",
    "Grid search was used to tune the SVC due to the different number of parameters depending on kernel, and random search for the rest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the train and test errors of the classifiers used compared with baseline errors of picking only one class. We can see that for most classifiers the test error is significantly below the baseline test error, ranging from about 0.26 to 0.35. The best model was the tuned support vector classifier and the worst was the decision tree, which we know is a weak learner and easily biased. \n",
    "\n",
    ">>>INSERT ERROR_TABLE.PNG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> INSERT CLASSIFIER_ERRORS.PNG\n",
    "\n",
    "In the above plot, we can see more easily see that the classifiers performed similarly. Every classifier was below their baseline. Decision tree classifier performed by far the worst out of all the classifiers and on certain runs is actually very close to the test_baseline value as seen in the plot below. The decision tree's error rates are highly variable. This is unstability is due to small differences in the randomness of the decision tree generating very different trees. \n",
    "\n",
    "In terms of fit on the training set, the trees were quite overfit. The most overfitted classifier was the random forest classifiers, giving 0 training error. Since we are optimizing max_depth as a parameter of random forest, it will try to pick the largest one as it is more likely to provide a single value within each leaf giving the lowest error. If we are tuning parameters based on error, it might be better to not tune the max_depth value to high values to prevent overfitting.\n",
    "\n",
    "Unsurprisingly, LDA and QDA both performed fairly well relative to the other classifiers. Although the dataset is quite small, from the data analysis we saw that most of the predictors were fairly normal in distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To highlight the weakness of decision trees as a learner,the decision tree was reran several times with fixed train and test sets. We see variance in both the train and test errors in the plot below, sometimes being very overfit and having low training errors, and other times not. This highlights how even small differences in how the tree is initially set up can create large differences in the predictive capabilities. This further reinforces the need for concepts such as bagging and boosting to work with these weak learners and tweak them so that as a whole they can form one strong learner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the data was transformed using principle component analysis with variance = 0.8 to reduce variance within the data and fight the \"curse of dimensionality\" and see the effect on the classifiers. The only two classifiers that improved were the two tree boosting methods: AdaBoost and XGBoost. In the non-transformed data, they both also had very low train error and were likely overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the data can be clearly split by the employee title as strata, an attempt to classify using stratified sampling was used. In particular, the role of \"Assistant Professor\" was a very small part of the data, but does represent an important title, as they are the ones in line for tenure. First the origial classification was ran again with straified sampling using the four titles as the strata. In the errors table, it seems that error is much higher in this than without the stratification.\n",
    "\n",
    "Then logistic regression was picked for classification on 1000 stratified samples. The error rates for train and test were most dense at around 0.3 and 0.4 respectively. This is worse than in the initial direct classification. This is likely due to the fact that assistant professors make up a small porportion of the data, but represents a quarter of the classes and likely the same points were picked multiple times in different samples. If we look at the minimum errors in the histogram, they are comparable to the regular classification. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
